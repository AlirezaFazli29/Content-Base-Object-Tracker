{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import CBComp as cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name()) \n",
    "else: print('cpu')\n",
    "default_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self,  weights=torchvision.models.VGG16_Weights.IMAGENET1K_V1):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        VGG = torchvision.models.vgg16(weights=weights)\n",
    "        self.feature = VGG.features\n",
    "        self.classifier = VGG.classifier[:5] \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def extract(self, x):\n",
    "        x = self.forward(x)\n",
    "        x = x.cpu().detach().numpy()\n",
    "        x = (x / (np.linalg.norm(x,axis=1))[:, np.newaxis])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor().to(default_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FeatureExtractor                         [1, 4096]                 --\n",
       "├─Sequential: 1-1                        [1, 512, 7, 7]            --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 224, 224]         1,792\n",
       "│    └─ReLU: 2-2                         [1, 64, 224, 224]         --\n",
       "│    └─Conv2d: 2-3                       [1, 64, 224, 224]         36,928\n",
       "│    └─ReLU: 2-4                         [1, 64, 224, 224]         --\n",
       "│    └─MaxPool2d: 2-5                    [1, 64, 112, 112]         --\n",
       "│    └─Conv2d: 2-6                       [1, 128, 112, 112]        73,856\n",
       "│    └─ReLU: 2-7                         [1, 128, 112, 112]        --\n",
       "│    └─Conv2d: 2-8                       [1, 128, 112, 112]        147,584\n",
       "│    └─ReLU: 2-9                         [1, 128, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-10                   [1, 128, 56, 56]          --\n",
       "│    └─Conv2d: 2-11                      [1, 256, 56, 56]          295,168\n",
       "│    └─ReLU: 2-12                        [1, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-13                      [1, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-14                        [1, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-15                      [1, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-16                        [1, 256, 56, 56]          --\n",
       "│    └─MaxPool2d: 2-17                   [1, 256, 28, 28]          --\n",
       "│    └─Conv2d: 2-18                      [1, 512, 28, 28]          1,180,160\n",
       "│    └─ReLU: 2-19                        [1, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-20                      [1, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-21                        [1, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-23                        [1, 512, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-24                   [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-25                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-26                        [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-27                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-28                        [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-29                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-30                        [1, 512, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-31                   [1, 512, 7, 7]            --\n",
       "├─Sequential: 1-2                        [1, 4096]                 --\n",
       "│    └─Linear: 2-32                      [1, 4096]                 102,764,544\n",
       "│    └─ReLU: 2-33                        [1, 4096]                 --\n",
       "│    └─Dropout: 2-34                     [1, 4096]                 --\n",
       "│    └─Linear: 2-35                      [1, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-36                        [1, 4096]                 --\n",
       "==========================================================================================\n",
       "Total params: 134,260,544\n",
       "Trainable params: 134,260,544\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 108.45\n",
       "Params size (MB): 537.04\n",
       "Estimated Total Size (MB): 646.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(feature_extractor, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224,224), antialias=True),\n",
    "                                transforms.ConvertImageDtype(torch.float),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lion1 = transform(read_image(\"C:/Users/Alireza/Desktop/1.jpg\"))\n",
    "lion2 = transform(read_image(\"C:/Users/Alireza/Desktop/2.jpg\"))\n",
    "fox = transform(read_image(\"C:/Users/Alireza/Desktop/3.jpeg\"))\n",
    "\n",
    "q_batch = torch.reshape(lion1,[1,3,224,224])\n",
    "d_batch = torch.stack((lion2,fox))\n",
    "with torch.no_grad():\n",
    "    f_q = feature_extractor.extract(q_batch.to(default_device))\n",
    "    f_d = feature_extractor.extract(d_batch.to(default_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(f_q, f_d):\n",
    "    dist = []\n",
    "    for feature in f_d:\n",
    "        dist.append(np.linalg.norm(f_q-feature))\n",
    "        indx = np.argmin(np.array(dist))\n",
    "    return indx, dist[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(f_q, f_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('C:/Users/Alireza/Desktop/Vivint_Outdoor_Camera_Pro_Sample_Footage_Driveway_Dayti_yWFv9eA72LA.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret ,frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = cv2.selectROI(\"Select Area\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 121, 117, 199)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand([244,244,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([244, 244, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 244, 244])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.permute(2,1,0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\Alireza/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "Alex = torchvision.models.alexnet(weights=torchvision.models.AlexNet_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.5, inplace=False)\n",
       "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (5): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alex.classifier[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "AlexNet                                  --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       23,296\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─MaxPool2d: 2-3                    --\n",
       "│    └─Conv2d: 2-4                       307,392\n",
       "│    └─ReLU: 2-5                         --\n",
       "│    └─MaxPool2d: 2-6                    --\n",
       "│    └─Conv2d: 2-7                       663,936\n",
       "│    └─ReLU: 2-8                         --\n",
       "│    └─Conv2d: 2-9                       884,992\n",
       "│    └─ReLU: 2-10                        --\n",
       "│    └─Conv2d: 2-11                      590,080\n",
       "│    └─ReLU: 2-12                        --\n",
       "│    └─MaxPool2d: 2-13                   --\n",
       "├─AdaptiveAvgPool2d: 1-2                 --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Dropout: 2-14                     --\n",
       "│    └─Linear: 2-15                      37,752,832\n",
       "│    └─ReLU: 2-16                        --\n",
       "│    └─Dropout: 2-17                     --\n",
       "│    └─Linear: 2-18                      16,781,312\n",
       "│    └─ReLU: 2-19                        --\n",
       "│    └─Linear: 2-20                      4,097,000\n",
       "=================================================================\n",
       "Total params: 61,100,840\n",
       "Trainable params: 61,100,840\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Alex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
